# G1 Whole Body Control Environment

ì´ í™˜ê²½ì€ Unitree G1 íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì˜ ìœ ì—°í•œ Whole Body Controlì„ ìœ„í•œ ê°•í™”í•™ìŠµ í™˜ê²½ì…ë‹ˆë‹¤.

## ğŸš€ í•µì‹¬ íŠ¹ì§•

### 4ê°œ ê´€ì ˆ ê·¸ë£¹
- **Hand**: ì†ê°€ë½ ê´€ì ˆ (DEX3 hands, 7 DOF per hand = 14 DOF total)
- **Arm**: íŒ” ê´€ì ˆ (7 DOF per arm = 14 DOF total)  
- **Waist**: í—ˆë¦¬ ê´€ì ˆ (3 DOF)
- **Leg**: ë‹¤ë¦¬ ê´€ì ˆ (6 DOF per leg = 12 DOF total)

### 3ê°€ì§€ ì •ì±… íƒ€ì… (ê·¸ë£¹ë³„ ì„¤ì • ê°€ëŠ¥)
- **RL Policy**: ê°•í™”í•™ìŠµìœ¼ë¡œ ì œì–´
- **IL Policy**: ëª¨ë°©í•™ìŠµìœ¼ë¡œ ì œì–´ (Separate/Unified ëª¨ë“œ ì§€ì›)
- **IK Policy**: ì—­ê¸°êµ¬í•™ ì†”ë²„ë¡œ ì œì–´ (Pink IK ë˜ëŠ” Simple IK ìë™ fallback)

### ìœ ì—°í•œ ì œì–´ êµ¬ì„±
- **Upper Body** = Hand + Arm (28 DOF)
- **Lower Body** = Waist + Leg (15 DOF)
- ê° ê·¸ë£¹ë³„ë¡œ ë…ë¦½ì ì¸ ì •ì±… íƒ€ì… ì„¤ì • ê°€ëŠ¥

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
g1/
â”œâ”€â”€ whole_body_env_cfg.py           # ë©”ì¸ whole body í™˜ê²½ ì„¤ì •
â”œâ”€â”€ upper_body_controller/          # Upper body ì»¨íŠ¸ë¡¤ëŸ¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ upper_body_IK.py           # IK ì»¨íŠ¸ë¡¤ëŸ¬ (Pink IK + Simple IK)
â”‚   â””â”€â”€ upper_body_IL.py           # IL ì»¨íŠ¸ë¡¤ëŸ¬ (Separate + Unified ëª¨ë“œ)
â”œâ”€â”€ mdp/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ whole_body_actions.py      # ë©€í‹° ì •ì±… whole body action í´ë˜ìŠ¤
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ rsl_rl_ppo_cfg.py          # ê¸°ë³¸ PPO ì„¤ì •
â”‚   â””â”€â”€ whole_body_rsl_rl_ppo_cfg.py # Whole body PPO ì„¤ì •
â”œâ”€â”€ test_whole_body_env.py         # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README_whole_body.md           # ì´ íŒŒì¼
```

## ğŸ¯ ë“±ë¡ëœ í™˜ê²½

### ì‹¤ì œ ì‹¤í–‰ í™˜ê²½ (Training/Evaluation)
- **`Isaac-Tracking-WholeBody-G1-UpperBodyIK-v0`**: Upper bodyëŠ” IK, Lower bodyëŠ” RL
- **`Isaac-Tracking-WholeBody-G1-UpperBodyIL-v0`**: Upper bodyëŠ” IL (Unified ëª¨ë“œ), Lower bodyëŠ” RL
- **`Isaac-Tracking-WholeBody-G1-FullRL-v0`**: ëª¨ë“  ê´€ì ˆ RL ì œì–´

### í”Œë ˆì´/í…ŒìŠ¤íŠ¸ í™˜ê²½ (Interactive Testing)
- **`Isaac-Tracking-WholeBody-G1-UpperBodyIK-Play-v0`**: UpperBodyIK í”Œë ˆì´ ë²„ì „ (50 envs)
- **`Isaac-Tracking-WholeBody-G1-UpperBodyIL-Play-v0`**: UpperBodyIL í”Œë ˆì´ ë²„ì „ (50 envs)
- **`Isaac-Tracking-WholeBody-G1-FullRL-Play-v0`**: FullRL í”Œë ˆì´ ë²„ì „ (50 envs)

> **ì°¸ê³ **: `G1WholeBodyEnvCfg`ì™€ `G1WholeBodyEnvCfg_PLAY`ëŠ” ë² ì´ìŠ¤ í´ë˜ìŠ¤ë¡œ, ì§ì ‘ ì‹¤í–‰ìš©ì´ ì•„ë‹™ë‹ˆë‹¤.

**ëª¨ë“  í™˜ê²½ì€ base_velocity ëª…ë ¹ë§Œ ì‚¬ìš©í•˜ë©°, end-effector ì œì–´ëŠ” IK/ILì„ í†µí•´ ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.**

## âš™ï¸ ì„¤ì • ì˜µì…˜

### Trajectory Generator ì„¤ì • (IK Policyìš©)
```python
# whole_body_env_cfg.pyì—ì„œ
actions.joint_pos.trajectory_generator_type = "circular"  # "circular", "linear", "custom"
actions.joint_pos.trajectory_generator_params = {
    "radius": 0.1,
    "frequency": 0.5
}
```

### Upper Body IL Policy ì„¤ì •
```python
# Separate ëª¨ë“œ (íŒ”ê³¼ ì† ê°œë³„ ëª¨ë¸)
actions.joint_pos.upper_body_policy_type = "separate"
actions.joint_pos.upper_body_policy_model_path = "/path/to/models"  # arm_model.pt, hand_model.pt í¬í•¨

# Unified ëª¨ë“œ (ë‹¨ì¼ í†µí•© ëª¨ë¸)
actions.joint_pos.upper_body_policy_type = "unified"
actions.joint_pos.upper_body_policy_model_path = "/path/to/unified_model.pt"
```

### Pink IK ì„¤ì •
```python
# Pink IK í™œì„±í™” (URDF ê²½ë¡œ í•„ìˆ˜)
actions.joint_pos.urdf_path = "/path/to/robot.urdf"
actions.joint_pos.mesh_path = "/path/to/meshes"  # ì„ íƒì‚¬í•­
```



## ğŸ”§ ì •ì±… ì„¤ì • ì˜ˆì‹œ

### 1. Lower Body RL + Upper Body IK (Pink IK ì‚¬ìš©)
```python
# G1WholeBodyActionsCfgì—ì„œ ì„¤ì •
joint_pos = g1_mdp.WholeBodyJointPositionActionCfg(
    hand_policy=g1_mdp.PolicyType.IK,    # IK ì œì–´ (HandëŠ” 0ìœ¼ë¡œ ì„¤ì •)
    arm_policy=g1_mdp.PolicyType.IK,     # IK ì œì–´ (Pink IK ì‚¬ìš©)
    waist_policy=g1_mdp.PolicyType.RL,   # RL ì œì–´  
    leg_policy=g1_mdp.PolicyType.RL,     # RL ì œì–´
    # Pink IK ì„¤ì • (ì„ íƒì‚¬í•­)
    urdf_path="/path/to/g1.urdf",        # G1 URDF íŒŒì¼ ê²½ë¡œ
    mesh_path="/path/to/meshes/",        # ë©”ì‹œ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
)
# RL Action Dimension: Waist(3) + Leg(12) = 15 DOF
```

### 2. Upper Body IL + Lower Body RL  
```python
joint_pos = g1_mdp.WholeBodyJointPositionActionCfg(
    hand_policy=g1_mdp.PolicyType.IL,    # IL ì œì–´
    arm_policy=g1_mdp.PolicyType.IL,     # IL ì œì–´
    waist_policy=g1_mdp.PolicyType.RL,   # RL ì œì–´
    leg_policy=g1_mdp.PolicyType.RL,     # RL ì œì–´
)
# RL Action Dimension: Waist(3) + Leg(12) = 15 DOF
```

### 3. Full RL Control
```python
joint_pos = g1_mdp.WholeBodyJointPositionActionCfg(
    hand_policy=g1_mdp.PolicyType.RL,    # RL ì œì–´
    arm_policy=g1_mdp.PolicyType.RL,     # RL ì œì–´
    waist_policy=g1_mdp.PolicyType.RL,   # RL ì œì–´
    leg_policy=g1_mdp.PolicyType.RL,     # RL ì œì–´
)
# RL Action Dimension: Hand(14) + Arm(14) + Waist(3) + Leg(12) = 43 DOF
```

## ğŸ”§ Pink IK ì„¤ì • (ì„ íƒì‚¬í•­)

Pink IKë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•˜ì„¸ìš”:

### 1. Pink IK ì„¤ì¹˜
```bash
pip install pink-python
```

### 2. URDF íŒŒì¼ ì¤€ë¹„
G1 ë¡œë´‡ì˜ URDF íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ ì„¤ì •ì—ì„œ URDF ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”:

```python
@configclass
class MyCustomActionsCfg(G1WholeBodyActionsCfg):
    joint_pos = g1_mdp.WholeBodyJointPositionActionCfg(
        # ... ê¸°íƒ€ ì„¤ì • ...
        urdf_path="/path/to/your/g1_robot.urdf",  # G1 URDF íŒŒì¼ ê²½ë¡œ
        mesh_path="/path/to/meshes/",             # ë©”ì‹œ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
    )
```

### 3. Fallback ë™ì‘
- URDF ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ Simple IK ì‚¬ìš©
- Pink IK ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ Simple IKë¡œ fallback
- Hand jointëŠ” Pink IK ì‚¬ìš© ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ëª¨ë‘ 0ìœ¼ë¡œ ì„¤ì •

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•
```python
import gymnasium as gym
import isaaclab_tasks

# Lower body RL + Upper body IK í™˜ê²½
env = gym.make("Isaac-Tracking-WholeBody-G1-UpperBodyIK-v0", num_envs=64)

# í™˜ê²½ ì •ë³´ í™•ì¸
print(f"RL Action dimension: {env.action_space}")
print(f"Observation spaces: {list(env.observation_space.keys())}")

# ì‹œë®¬ë ˆì´ì…˜
obs, _ = env.reset()
for step in range(1000):
    # RL ì •ì±…ì´ ì œì–´í•˜ëŠ” ê´€ì ˆì— ëŒ€í•œ ì•¡ì…˜ë§Œ í•„ìš”
    actions = torch.rand(env.action_space.shape, device=env.device) * 0.2 - 0.1
    obs, rewards, terminated, truncated, info = env.step(actions)
    
env.close()
```

### 2. Play í™˜ê²½ ì‚¬ìš©ë²• (ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸)
```python
import gymnasium as gym
import isaaclab_tasks

# Play í™˜ê²½ì€ ì ì€ ìˆ˜ì˜ í™˜ê²½ìœ¼ë¡œ ì‹œê°ì  í…ŒìŠ¤íŠ¸ì— ì í•©
env = gym.make("Isaac-Tracking-WholeBody-G1-UpperBodyIK-Play-v0")
# ìë™ìœ¼ë¡œ 50ê°œ í™˜ê²½, ë…¸ì´ì¦ˆ ë¹„í™œì„±í™”, ì‹œê°í™” ìµœì í™”
```

### 3. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
# Upper body IK í™˜ê²½ í•™ìŠµ
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Tracking-WholeBody-G1-UpperBodyIK-v0

# Upper body IL í™˜ê²½ í•™ìŠµ
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Tracking-WholeBody-G1-UpperBodyIL-v0

# Full RL í™˜ê²½ í•™ìŠµ
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py --task Isaac-Tracking-WholeBody-G1-FullRL-v0
```

### 4. Play í™˜ê²½ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
```bash
# GUI ëª¨ë“œë¡œ ì‹œê°ì  í…ŒìŠ¤íŠ¸
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Tracking-WholeBody-G1-UpperBodyIK-Play-v0 --num_envs 16

# ë‹¤ë¥¸ Play í™˜ê²½ë“¤
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Tracking-WholeBody-G1-UpperBodyIL-Play-v0 --num_envs 16
./isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/play.py --task Isaac-Tracking-WholeBody-G1-FullRL-Play-v0 --num_envs 16
```

## ğŸ” ë‚´ë¶€ ë™ì‘ ì›ë¦¬

### Action Processing Flow
1. **RL Policy Actions**: `env.step(actions)`ì—ì„œ RL-controlled jointsë§Œ ì „ë‹¬
2. **IK Controller**: ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ Cartesian trajectory ìƒì„± â†’ IK í•´ê²° â†’ joint targets
3. **IL Controller**: í˜„ì¬ observations â†’ pre-trained IL model â†’ joint targets  
4. **Action Combination**: ëª¨ë“  ê·¸ë£¹ì˜ targets ê²°í•© â†’ robotì— ì „ë‹¬

### Policy Typeë³„ íŠ¹ì§•
- **RL**: `env.step()`ì˜ actionsì—ì„œ ì˜¤ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ì •ì±…
- **IK**: ë¯¸ë¦¬ ì •ì˜ëœ Cartesian trajectoryë¥¼ ë”°ë¥´ëŠ” deterministic ì œì–´
  - **Pink IK**: ê³ ê¸‰ ë¯¸ë¶„ ê°€ëŠ¥í•œ IK ì†”ë²„ (URDF ê²½ë¡œ ì œê³µ ì‹œ ì‚¬ìš©)
  - **Simple IK**: ê¸°í•˜í•™ì  IK ì†”ë²„ (fallback)
  - **Hand**: ëª¨ë“  joint targetì„ 0ìœ¼ë¡œ ì„¤ì •
- **IL**: Pre-trained modelì„ ì‚¬ìš©í•œ ëª¨ë°©í•™ìŠµ ê¸°ë°˜ ì œì–´

### Observation Space
- **Policy Network**: ë…¸ì´ì¦ˆ í¬í•¨, ëª¨ë“  joint states ê´€ì°° (awareness)
- **Critic Network**: íŠ¹ê¶Œ ì •ë³´ í¬í•¨, ë…¸ì´ì¦ˆ ì—†ëŠ” ê´€ì°°
- **Action History**: RL-controlled jointsë§Œ í¬í•¨

## ğŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜

### 1. ìƒˆë¡œìš´ ì •ì±… ì¡°í•© ë§Œë“¤ê¸°
```python
@configclass
class MyCustomEnvCfg(G1WholeBodyEnvCfg):
    def __post_init__(self) -> None:
        super().__post_init__()
        # ì›í•˜ëŠ” ì •ì±… ì¡°í•©ìœ¼ë¡œ ì„¤ì •
        self.actions.joint_pos.hand_policy = g1_mdp.PolicyType.RL
        self.actions.joint_pos.arm_policy = g1_mdp.PolicyType.IK
        self.actions.joint_pos.waist_policy = g1_mdp.PolicyType.IL
        self.actions.joint_pos.leg_policy = g1_mdp.PolicyType.RL
```

### 2. IK Controller ìˆ˜ì •
```python
# upper_body_IK.pyì—ì„œ ìˆ˜ì •
class CustomTrajectoryGenerator(TrajectoryGenerator):
    def generate(self, current_time: float, **kwargs) -> Dict[str, torch.Tensor]:
        # ì»¤ìŠ¤í…€ trajectory êµ¬í˜„
        pass
```

### 3. IL Model êµì²´
```python
# upper_body_IL.pyì—ì„œ ìˆ˜ì •
class CustomILModel(ILModel):
    def predict(self, observations: torch.Tensor) -> torch.Tensor:
        # ì»¤ìŠ¤í…€ IL model êµ¬í˜„
        pass
```

### 4. ë³´ìƒ í•¨ìˆ˜ ìˆ˜ì •
```python
# whole_body_env_cfg.pyì˜ G1WholeBodyRewardsCfgì—ì„œ ìˆ˜ì •
@configclass
class CustomRewardsCfg(G1WholeBodyRewardsCfg):
    # ìƒˆë¡œìš´ ë³´ìƒ í•¨ìˆ˜ ì¶”ê°€/ìˆ˜ì •
    my_custom_reward = RewTerm(...)
```

## ğŸ“Š í™˜ê²½ë³„ ë¹„êµ

| í™˜ê²½ | Hand | Arm | Waist | Leg | RL Dim | ìš©ë„ |
|------|------|-----|-------|-----|--------|------|
| UpperBodyIK | IK | IK | RL | RL | 15 | ë³´í–‰ í•™ìŠµ |
| UpperBodyIL | IL | IL | RL | RL | 15 | IL+RL ê²°í•© |
| FullRL | RL | RL | RL | RL | 43 | ì „ì‹  í•™ìŠµ |
| WholeBody | IK | IK | RL | RL | 15 | ê¸°ë³¸ ì„¤ì • |

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **Action Dimension í™•ì¸**: í™˜ê²½ë§ˆë‹¤ RL action dimensionì´ ë‹¤ë¦„
2. **IL Model Loading**: IL policy ì‚¬ìš© ì‹œ pre-trained model ë¡œë“œ í•„ìš”
3. **IK Trajectory**: IK policyëŠ” ë¯¸ë¦¬ ì •ì˜ëœ trajectory ì‚¬ìš©
4. **Performance**: Full RLì€ ë” ë§ì€ DOFë¡œ ì¸í•´ í•™ìŠµì´ ì–´ë ¤ì›€
5. **Observation**: ëª¨ë“  joint statesê°€ observationì— í¬í•¨ë˜ì§€ë§Œ actionì€ RL jointsë§Œ

## ğŸ”„ í™˜ê²½ ì‚¬ìš©ë²•

Whole Body í™˜ê²½ì€ ë‹¤ì–‘í•œ ì •ì±… ì¡°í•©ì„ ì§€ì›í•©ë‹ˆë‹¤:

```python
# Upper Body IK + Lower Body RL (ê°€ì¥ ì¼ë°˜ì )
env = gym.make("Isaac-Tracking-WholeBody-G1-UpperBodyIK-v0")

# Upper Body IL + Lower Body RL
env = gym.make("Isaac-Tracking-WholeBody-G1-UpperBodyIL-v0")

# Full RL Control (ê³ ê¸‰ ì‚¬ìš©ììš©)
env = gym.make("Isaac-Tracking-WholeBody-G1-FullRL-v0")
```
